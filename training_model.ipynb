{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\vasun\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\vasun\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vasun\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vasun\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\vasun\\anaconda3\\lib\\site-packages (9.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\vasun\\anaconda3\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vasun\\appdata\\roaming\\python\\python39\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vasun\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vasun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.layers import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a text file into memory\n",
    "\n",
    "def load_doc(doc):\n",
    "    file = open(doc, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "#get all images with captions\n",
    "\n",
    "def img_captions(doc):\n",
    "    file = load_doc(doc)\n",
    "    captions = file.split('\\n')\n",
    "    description = {}\n",
    "    for cap in captions[:-1]:\n",
    "        img, cap = cap.split('\\t')\n",
    "        if img[:-2] not in description:\n",
    "            description[img[:-2]] = [cap]\n",
    "        else:\n",
    "            description[img[:-2]].append(cap)\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations and words containing numbers\n",
    "\n",
    "def clean(captions):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for img, caps in captions.items():\n",
    "        for i, img_cap in enumerate(caps):\n",
    "            img_cap.replace(\"-\", \" \")\n",
    "            desc = img_cap.split()\n",
    "            \n",
    "            #all letters in lowercase\n",
    "            desc = [word.lower() for word in desc]\n",
    "            \n",
    "            #remove punctuation\n",
    "            desc = [word.translate(table) for word in desc]\n",
    "            \n",
    "            #remove 's and 'a'\n",
    "            desc = [word for word in desc if(len(word)>1)]\n",
    "            \n",
    "            #remove tokens with numbers\n",
    "            desc = [word for word in desc if(word.isalpha())]\n",
    "            \n",
    "            img_cap = ' '.join(desc)\n",
    "            captions[img][i] = img_cap\n",
    "            \n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_vocab(description):\n",
    "    vocab = set()\n",
    "    for key in description.keys():\n",
    "        [vocab.update(d.split()) for d in description[key]]\n",
    "        \n",
    "    return vocab\n",
    "\n",
    "def save_desc(description, doc):\n",
    "    lines = list()\n",
    "    \n",
    "    for key, desc_list in description.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + '\\t' + desc)\n",
    "        data = \"\\n\".join(lines)\n",
    "        file = open(doc, \"w\")\n",
    "        file.write(data)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of descriptions = 8092\n",
      "Length of vocabulary = 8763\n"
     ]
    }
   ],
   "source": [
    "data_text = r\"C:\\Users\\vasun\\Desktop\\Image Caption Generator\\Flickr8k_text\"\n",
    "data_img = r\"C:\\Users\\vasun\\Desktop\\Image Caption Generator\\Flickr8k_Dataset\\Flicker8k_Dataset\"\n",
    "\n",
    "doc = data_text + \"/\" + \"Flickr8k.token.txt\"\n",
    "description = img_captions(doc)\n",
    "print(\"Length of descriptions =\", len(description))\n",
    "\n",
    "clean_desc = clean(description)\n",
    "vocab = text_vocab(clean_desc)\n",
    "print(\"Length of vocabulary =\", len(vocab))\n",
    "\n",
    "save_desc(clean_desc, \"descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(directory):\n",
    "    model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "    for img in tqdm(os.listdir(directory)):\n",
    "        filename = directory + \"/\" + img\n",
    "        image = Image.open(filename)\n",
    "        image = image.resize((299, 299))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image/127.5\n",
    "        image = image - 1.0\n",
    "        \n",
    "        feature = model.predict(image)\n",
    "        features[img] = feature\n",
    "    \n",
    "    return features\n",
    "\n",
    "features = extract(data_img)\n",
    "dump(features, open(\"features.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load(open(\"features.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(filename):\n",
    "    file = load_doc(filename)\n",
    "    photos = file.split(\"\\n\")[:-1]\n",
    "    return photos\n",
    "\n",
    "def load_clean_desc(filename, photos):\n",
    "    file = load_doc(filename)\n",
    "    description = {}\n",
    "    for line in file.split(\"\\n\"):\n",
    "        words = line.split()\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "        \n",
    "        img, image_captions = words[0], words[1:]\n",
    "        \n",
    "        if img in photos:\n",
    "            if img not in description:\n",
    "                description[img] = []\n",
    "            desc = '<start> ' + \" \".join(image_captions) + ' <end>'\n",
    "            description[img].append(desc)\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(photos):\n",
    "    all_feature = load(open(\"features.p\", \"rb\"))\n",
    "    features = {k: all_feature[k] for k in photos}\n",
    "    return features\n",
    "\n",
    "filename = data_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
    "train_img = load_img(filename)\n",
    "train_desc = load_clean_desc(\"descriptions.txt\", train_img)\n",
    "train_feature = load_features(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary = 7577\n"
     ]
    }
   ],
   "source": [
    "def dict2list(description):\n",
    "    all_desc = []\n",
    "    for key in description:\n",
    "        [all_desc.append(d) for d in description[key]]\n",
    "    return all_desc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def create_token(description):\n",
    "    desc_list = dict2list(description)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = create_token(train_desc)\n",
    "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Size of Vocabulary =\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of description = 32\n"
     ]
    }
   ],
   "source": [
    "def max_length(description):\n",
    "    desc_list = dict2list(description)\n",
    "    return max(len(d.split()) for d in desc_list)\n",
    "\n",
    "max_length = max_length(description)\n",
    "print(\"Maximum length of description =\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47, 2048), (47, 32), (47, 7577))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(description, features, tokenizer, max_length):\n",
    "    while 1:\n",
    "        for key, desc in description.items():\n",
    "            feat = features[key][0]\n",
    "            input_img, input_seq, output_desc = create_seq(tokenizer, max_length, desc, feat)\n",
    "            yield[[input_img, input_seq], output_desc]\n",
    "\n",
    "def create_seq(tokenizer, max_length, desc_list, feature):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for desc in desc_list:\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen = max_length)[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            X1.append(feature)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "[a,b], c = next(data_generator(train_desc, features, tokenizer, max_length))\n",
    "a.shape, b.shape, c.shape            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    #features from the CNN model squeezed from 2048 to 256 nodes\n",
    "    input_1 = Input(shape=(2048,))\n",
    "    feat_1 = Dropout(0.5)(input_1)\n",
    "    feat_2 = Dense(256, activation='relu')(feat_1)\n",
    "    \n",
    "    #LSTM sequence model\n",
    "    input_2 = Input(shape=(max_length,))\n",
    "    seq_1 = Embedding(vocab_size, 256, mask_zero=True)(input_2)\n",
    "    seq_2 = Dropout(0.5)(seq_1)\n",
    "    seq_3 = LSTM(256)(seq_2)\n",
    "    \n",
    "    #Merging CNN model and LSTM model\n",
    "    decoder_1 = add([feat_2, seq_3])\n",
    "    decoder_2 = Dense(256, activation='relu')(decoder_1)\n",
    "    output = Dense(vocab_size, activation='softmax')(decoder_2)\n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2], outputs = output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file=\"model.png\", show_shapes=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset:  6000\n",
      "Descriptions:  6000\n",
      "Photos:  6000\n",
      "Vocabulary Size:  7577\n",
      "Description Length:  32\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 2048)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 32, 256)      1939712     ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 2048)         0           ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32, 256)      0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 256)          524544      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 256)          525312      ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 256)          0           ['dense_21[0][0]',               \n",
      "                                                                  'lstm_7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 256)          65792       ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 7577)         1947289     ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,002,649\n",
      "Trainable params: 5,002,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "print('Datset: ', len(train_img))\n",
    "print('Descriptions: ', len(train_desc))\n",
    "print('Photos: ', len(train_feature))\n",
    "print('Vocabulary Size: ', vocab_size)\n",
    "print('Description Length: ', max_length)\n",
    "\n",
    "model = define_model(vocab_size, max_length)\n",
    "epochs = 10\n",
    "steps = len(train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"models\")\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_desc, train_feature, tokenizer, max_length)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save(\"models/model_\" + str(i) + \".h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "428f85aed2af2e11a823a6d83e8004eb1980732d731fb59851d1cd62b92a459e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
